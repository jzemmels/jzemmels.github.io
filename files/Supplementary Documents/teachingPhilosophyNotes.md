- Why do you teach the way you do?

- What should students expect of you as a teacher?

- What is a method of teaching you rely on frequently? Why don't you use a different method?

- What do you want students to learn? How do you know your goals for students are being met?

- What should your students be able to know or do as a result of taking your class?

- How can your teaching facilitate student learning?


Fundamental to my teaching philosophy is the belief that students want to learn, yet may not apply themselves out of a fear of failure.
When students feel that it is safe for them to fail, they are more inclined to engage with the course material.
As a teacher, I want to inspire my students to fail.
I accomplish this by planning instruction and assessment opportunities that encourage trial and error.

One way in which I accomplish a "safe-to-fail" learning environment is to focus on low-stakes, formative assessments that provide students with an opportunity to check their understanding.
For example, I created a series of "quizzes" and "Excel labs" for a course geared towards forensic examiners to learn about statistics and probability.
The quizzes assessed students' understanding of the theoretical aspects of the course ("Can a student properly apply Bayes' Rule to calculate a conditional probability?").
The Excel labs put the theory into practice by analyzing real forensic or criminological data using the tools discussed in class.
Both types of assessments focused on experimentation ("How does 'x' change when you change 'y?'") and interpretation ("Why does 'x' change in this manner?"), which I consider to be two of the most important skills for a successful data analysis.
In a lecture setting, I prefer to weave formative assessments into instruction so that students receive immediate, specific feedback on their understanding.

However, low-stakes assessments only go so far - students eventually need to demonstrate their understanding in a higher-stakes, summative assessment.
As a guiding principle for creating summative assessments, I consider skills that I want students to develop during a course: the ability to cooperate and communicate with others or to explore, manipulate, and interpret data.
While content knowledge is also an important course outcome, I believe skills persist much longer, and therefore should be the primary target of assessment, than memorization of formulas, facts, or functions.
For example, the final project of a Master's-level Visual Business Analytics course that I taught required teams of students to find, clean, analyze, and summarize a data set using data visualization best practices and R programming packages such as dplyr, ggplot2, rmarkdown, and shiny.
The final product included a report, presentation, and interactive web application.
Students were assessed not only on the quality of their final summary, but also on the process of trial and error that led to the summary.
In this way, students were explicitly encouraged to fail at answering a data-related question, reflect upon their failure, and try another solution.

Another way I that encourage "failure" is to intentionally pose open-ended, often ambiguous data problems.
As a simple example: rather than asking students in an introductory methods class to determine whether a data set contains outliers, I might ask students to hypothesize why the data set contains outliers.
The former question requires simple calculations given a suitable defintion of "outlier" while the latter requires students to scrutinize the data collection and recording process - a task that anyone dealing with real data will undoubtedly perform.
I believe that most data-related questions do not have a single, "correct" answer and that my students may provide different, yet equally valid, solutions from my own.
As an avid student myself, learning from others' perspectives is one of the biggest joys I receive from teaching.
It is my job to strike the delicate balance between giving space to grapple with nuanced problems and providing guiderails to achieve the learning outcomes.
Continuing with the outlier example, I would pose a question like "Why does this data set contain outliers?" after discussing common errors in data collection and allow students to explore the data set on their own to develop hypotheses.
